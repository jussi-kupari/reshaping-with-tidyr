---
title: "R4DS-QuickRef -- Ch2 Importing Data: readr"
output: html_notebook
---

```{r}
library(readr)
```

## Functions for Reading Data

**The readr package provides the following functions for reading tabular data:**

read_csv() Comma-separated values

read_csv2() Semicolon-separated values

read_tsv() Tab-separated values

read_delim() General column delimiters

read_table() Space-separated values (fixed-length columns)

read_fwf() Fixed-width-files

```{r}
# basic usage of read_csv
(data <- read_csv("data/data.csv"))
```

```{r}
# You can get information about inferred types using the spec() function:
spec(data)
```

```{r}
# If you don't want the type inference info then do
read_csv("data/data.csv", show_col_types = FALSE)
```

```{r}
# For tab-separated files read_csv doesn't work
read_csv("data/data.tsv")
```

```{r}
# Use read_tsv instead
read_tsv("data/data.tsv")
```

```{r}
# Or use read_delim with delim = "\t"
read_delim("data/data.tsv", delim = "\t")
```


```{r}
# Compressed (.gz, .bz2, .xz, or .zip) files will be uncompressed by read_csv.
read_csv("data/data.csv.gz", show_col_types = FALSE)
```

```{r}
# a URL (http://, https://, ftp://, or ftps://) file will automatically be downloaded
read_csv(
  "https://basv53.uni.lu/lectures/data/example.csv",
  show_col_types = FALSE
  )
```

```{r}
# You can also provide a string as the file object.
# This is rarely useful in a data analysis project, but you can use it to create 
# examples or for debugging.
read_csv(
  "A, B, C, D
 1, a, a, 1.2
 2, b, b, 2.1
 3, c, c, 13.0
",
show_col_types = FALSE
)
```

```{r}
# You can use read_delim as a general import function
# You can give it the delimiter, or let it guess
read_delim("data/data.csv.gz")
```

```{r}
read_delim("data/data.csv", delim = ",")
```

```{r}
# read_delim tries to guess the delimiter if not explicitly given
read_delim("data/data.tsv")
```


## File Headers

```{r}
# If the first line is not column names, you can use the option col_names = FALSE.
# Note that all columns now have type <chr> because the header is part of the data
read_csv(
  "data/data.csv", 
  col_names = FALSE, 
  show_col_types = FALSE
)
```

```{r}
# Without the header we would get the result as before, with autogenerated names 
read_csv(
  "1, a, a, 1.2
   2, b, b, 2.1
   3, c, c, 13.0",
show_col_types = FALSE,
col_names = FALSE
)
```
```{r}
# If you want to provide names yourself, use col_names with a vector of names
read_csv(
  "1, a, a, 1.2
   2, b, b, 2.1
   3, c, c, 13.0",
show_col_types = FALSE,
col_names = c("X", "Y", "Z", "W")
)
```

```{r}
# To rename columns in a file that has names, you must skip the original names
read_csv(
  "data/data.csv",
  show_col_types = FALSE,
  skip = 1,
  col_names = c("X", "Y", "Z", "W")
)
```
```{r}
# You can also limit the number of rows to be read using n_max
read_csv(
  "data/data.csv",
  show_col_types = FALSE,
  skip = 1,
  col_names = c("X", "Y", "Z", "W"),
  n_max = 2
)
```

```{r}
# You can skip possible comments if you provide the comment option:
read_csv(
 "A, B, C, D   # this is a comment
  1, a, a, 1.2 # another comment
  2, b, b, 2.1
  3, c, c, 13.0",
 comment = "#",
 show_col_types = FALSE
 )
```

```{r}
# You can have a full line comment, but it must start at the left edge
# This will not work properly 
read_csv(
 "A, B, C, D   
 # this is a comment that doesn't start from the very left
  1, a, a, 1.2 # another comment
  2, b, b, 2.1
  3, c, c, 13.0",
 comment = "#",
 show_col_types = FALSE
 )
```

```{r}
# This works 
read_csv(
 "A, B, C, D   
# full line comment starting from the very left
  1, a, a, 1.2 # another comment
  2, b, b, 2.1
  3, c, c, 13.0",
 comment = "#",
 show_col_types = FALSE
 )
```
## Column Types 
When read_csv parses a file, it infers the type of each column. This inference can be 
slow, or worse the inference can be incorrect. If you know a priori what the types should 
be, you can specify this using the col_types option.

### String-Based Column Type Specification

**Character Type**

c Character

i Integer

n Number

d Double

l Logical

f Factor

D Date

T Datetime

t Time

? Guess (default)

_/- Skip the column

```{r}
# By default, read_csv guesses. This can be made explicit
read_csv("data/data.csv", col_types = "????")
```

```{r}
# This result can be made explicit with "dccd"
read_csv("data/data.csv", col_types = "dccd")
```

```{r}
# If you want an integer type for column A, you can use "iccd"
read_csv("data/data.csv", col_types = "iccd")
```

```{r}
# Column D can't be read as an <int> by read_csv. This will result in NAs
read_csv("data/data.csv", col_types = "icci")
```

If you specify that a column should have type d, the numbers in the column must be 
integers or decimal numbers. If you use the type n (the default that read_csv will guess), 
you will also get doubles, but the latter type can handle strings that can be interpreted 
as numbers such as dollar amounts, percentages, and group separators in numbers. The 
column type n will ignore leading and trailing text and handle number separators

```{r}
# Type n can handle strings that can be interpreted as numbers, ignoring extra symbols
read_csv(
 'A, B, C, D, E
 $1,a,a,1.2%,"1,100,200"
 $2,b,b,2.1%,"140,000"
 $3,c,c,13.0%,"2,005,000"',
 col_types ="nccnn"
 )
```

```{r}
# Use 'locale' to specify decimal and grouping indicators
# See the ?locale documentation for more options.
read_csv(
 'A, B, C, D, E
 $1,a,a," 1,2%","1.100.200"
 $2,b,b," 2,1%"," 140.000"
 $3,c,c,"13,0%","2.005.000"',
 locale = locale(decimal_mark = ",", grouping_mark = "."),
 col_types ="nccnn")
```

```{r}
# If a column only contains TRUE and FALSE (case doesn’t matter) type guess is <lgl>
read_csv(
 'A, B, C, D
 TRUE, a, a, 1.2
 false, b, b, 2.1
 true, c, c, 13',
 show_col_types = FALSE
)
```

```{r}
# Numeric logical values [0, 1] can be interpreted explicitly
read_csv(
 'A, B, C, D
 1, a, a, 1.2
 0, b, b, 2.1
 1, c, c, 13',
 col_types ="lccn"
)
```

```{r}
# You can mix-and-match numeric and character logical values
read_csv(
 'A, B, C, D
 true, a, a, 1.2
 0, b, b, 2.1
 1, c, c, 13
 FALSE, c, b, 14',
 col_types ="lccn"
)
```

```{r}
# The D, t, and T types are for dates, time points, and datetime, in that order.
read_csv(
 'D, T, t
 "2018-08-23", "2018-08-23T14:30", 14:30',
 col_types ="DTt"
)
```

```{r}
# You can use 'locale' to change how read_csv parses dates (D) and time (t).
# Date and time formats can be specified using date_format and time_format.
# For datetimes (T), we cannot specify the format using locale.
read_csv(
 'D, t
 "23 Oct 2018", 2pm',
 col_types = "Dt",
 locale = locale(
   date_format = "%d %b %Y",
   time_format = "%I%p"
 )
)
```

```{r}
# If you want to create a factor type column, you use the "f" type specification.
read_csv(
'A, B, C, D
 1, a, a, 1.2
 0, b, b, 2.1
 1, c, c, 13',
 col_types = "lcfn"
)
```

```{r}
# To skip columns, use "_" or "-"
read_csv("data/data.csv", col_types = "_cc-")
```

If you specify the column types using a string, you should specify the types of all 
columns. If you only want to define the types of a subset of columns, you can use the 
function cols() to specify types. You call this function with named parameters, where 
the names are column names and the arguments are types.

```{r}
# Define only a subset of columns explicitly
read_csv("data/data.csv", col_types = cols(A = "c", B = "f"))
```
### Function-Based Column Type Specification

You can use longer type names that you specify using function calls. 
These functions have names that start with col_, so you can use autocomplete to get 
a list of them. The types you can specify using functions are the same as those you can 
specify using characters, of course, and the functions are as follows:

**Function Type**

col_character() Character

col_integer() Integer

col_number() Number

col_double() Double

col_logical() Logical

col_factor() Factor

col_date() Date

col_datetime() Datetime

col_time() Time

col_guess() Guess (default)

col_skip() Skip the column

```{r}
# Wrap the function-based specifications to 'cols'
read_csv(
  "data/data.csv", 
  col_types = cols(A = col_integer(), B = col_factor())
  )
```
For factors, date, time, and datetime types, you have more control over the 
format using the 'col_' functions. You can use arguments to these functions for specifying 
how read_csv should parse dates and how it should construct factors.

For factors, you can explicitly set the levels. If you do not, then the column parser 
will set the levels in the order it sees the different strings in the column. 
For example, in data/data.csv the strings in columns C and D are in the order a, b, and c:

```{r}
(my_data <-
  read_csv(
 file = "data/data.csv",
 col_types = cols(C = col_factor())
))
```

```{r}
my_data$C
```

```{r}
my_data <-
  read_csv(
  'A, B, C
 Foo, 12.4, Medium
 Bar, 5.2, Small
 Baz, 42.0, Large',
 col_types = cols(
   C = col_factor(levels = c("Small", "Medium", "Large")
   )))
```

```{r}
my_data$C
```


```{r}
# For a different order, we can give col_factor() a 'levels' or 'ordered' argument.
(my_data <-
  read_csv(
 file = "data/data.csv",
 col_types = cols(
   A = col_factor(ordered = TRUE),
   C = col_factor(levels = c("b", "c", "a"))
   )
  )
)
```

```{r}
my_data$A
my_data$C
```

### Parsing Time and Dates

**Code Time format Example string Interpretation**

%Y 4-digit year 1975 The year 1975

%y 2-digit year5 75 Also the year 1975

%m 2-digit month 02 February

%b Abbreviated month name6 Feb February

%B Full month name February February

%d 2-digit day 15 The 15th of a month

%H Hour number on a 24-hour clock 18 Six o’clock in the evening

%I Hour number on a 12-hour clock7 6 pm 18:00 hours

%p AM/PM indicator 6 pm 18:00 hours

%M Two-digit minutes 18:30 Half past six

%S Integer seconds 18:30:10 Ten seconds past 18:00

%Z Time zone as name8 America/Chicago Central Time

%z Time zone as offset from UTC “+0100” Central European Time


**There are shortcuts for frequently used formats:**

Shortcut Format

%D %m/%d/%y

%x %y/%m/%d

%F %Y-%m-%d

%R %H:%M

%T %H:%M:%S


### Parsin date, time and datetime

```{r}
# Time
parse_time(c("18:00"), format = "%R")
parse_time(c("18:00:30"), format = "%T")
parse_time(c("6 pm"), format = "%I %p")
parse_time(c("18"), format = "%R")
```

```{r}
# Date
parse_date(c("1975-02-05"), format = "%Y-%m-%d")
parse_date(c("1975-02-05"))
parse_date(c("75-02"), format = "%y-%m")
```

Dates written on the form 05/02/75 can mean both February 5, 1975, and May 2, 
1975, depending on where you are in the world. Europe uses the sensible DD/MM/
YY format, where the order goes from the smallest time unit, days, to the medium time 
units, months, and then to years. In the United States, they use the MM/DD/YY format. 
To get the 5th of February, you need one of these formats:

```{r}
parse_date(c("05/02/75"), format = "%d/%m/%y") # Europe
parse_date(c("02/05/75"), format = "%m/%d/%y") # USA
```

Date specifications that only use numbers are not affected by the local language, but 
if you include the name of months, they are. The name of months and their abbreviation 
varies from language to language, obviously.

```{r}
# English and Danish
parse_date(c("Feb 5 1975"), format = "%b %d %Y", locale = locale("en"))
parse_date(c("5. feb. 1975"),format ="%d. %b %Y",locale =locale("da"))
```

“Datetimes” can be parsed using combinations of date and time strings. With these, 
you also want to consider time zones. You can either specify that time zones are relative to UTC with %z or location based, with %Z if the time zone is given in the input, or you can use locale() if it is the same for all the input.

If you specify a time zone based on a location, R will automatically adjust for 
daylight saving time, but if you use dates relative to UTC, you will not—UTC does not 
have daylight savings. Central European Time (CET) is “+0100” and with daylight saving 
time “+0200”. US Pacific Time (PST) is “-0800”, but with daylight saving time (PDT), it is 
“-0700”. When you switch back and forth between daylight savings is determined by your 
location.

```{r}
# Datetime
parse_datetime(c("Feb 15 1975 18:00 US/Pacific"), format = "%b %d %Y %R %Z")
parse_datetime(c("Feb 15 1975 18:00 -0800"), format = "%b %d %Y %R %z")
parse_datetime(c("Jun 15 1975 18:00 US/Pacific"), format ="%b %d %Y %R %Z")
parse_datetime(c("Jun 15 1975 18:00 -0700"), format ="%b %d %Y %R %z")
```

If you use locale() to specify a time zone, you cannot use zones relative to UTC. The 
point of using locale() is local formats, not time zones. The parser will still handle 
daylight savings for you, however. These two are the same datetimes:

```{r}
parse_datetime(
  c("Aug 15 1975 18:00"),
  format = "%b %d %Y %R",
  locale = locale(tz = "US/Pacific")
  )
```

```{r}
parse_datetime(
 c("Aug 15 1975 18:00 US/Pacific"),
 format ="%b %d %Y %R %Z"
)
```

```{r}
# The dates are equal even if printed differently
parse_datetime(
  c("Aug 15 1975 18:00"),
  format = "%b %d %Y %R",
  locale = locale(tz = "US/Pacific")
  ) ==
  parse_datetime(
 c("Aug 15 1975 18:00 US/Pacific"),
 format ="%b %d %Y %R %Z"
)
```

### Space-Separated Columns

The preceding functions all read delimiter-separated columns. They expect a single 
character to separate one column from the next. If the argument trim_ws is true, they 
ignore whitespace. This argument is true by default for read_csv, read_csv2, and read_
tsv, but false for read_delim.

The function read_table instead separates columns by one or more spaces. It takes 
many of the same arguments as read_csv or read_tsv and mostly differs in what it 
considers the column separator—this function uses whitespace instead of a specific 
field separator such as a comma or a semicolon.

```{r}
read_table(
  "A B C D
 1 2 3 4
 15 16 17 18"
)
```

```{r}
# Disable colnames
read_table(
  "A B C D
 1 2 3 4
 15 16 17 18",
 col_names = FALSE
)
```